---
phase: v3.0-08-testing-polish
plan: 02
type: execute
wave: 2
depends_on: ["08-01"]
files_modified:
  - src/main/services/__tests__/session-performance.test.ts
autonomous: true
user_setup: []

must_haves:
  truths:
    - "Performance tests validate large session handling (10k messages)"
    - "Compaction performance measured and within acceptable limits"
    - "Concurrent session access tested without race conditions"
    - "File I/O performance benchmarked"
  artifacts:
    - path: "src/main/services/__tests__/session-performance.test.ts"
      provides: "Performance test suite"
      min_lines: 150
  key_links:
    - from: "src/main/services/__tests__/session-performance.test.ts"
      to: "src/main/services/session-manager.ts"
      via: "imports and stress tests SessionManager"
      pattern: "import.*SessionManager"
---

<objective>
Implement performance tests validating SessionManager behavior under load: large sessions, compaction timing, concurrent access, and file I/O.

Purpose: Ensure the session management system performs well at scale and identify potential bottlenecks.
Output: Performance test file with benchmarks and stress tests.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/v3.0-08-testing-polish/08-01-SUMMARY.md
@src/main/services/session-manager.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Large session stress tests</name>
  <files>src/main/services/__tests__/session-performance.test.ts</files>
  <action>
Create performance test suite with large session handling:

1. Test setup:
   - Use test fixtures with realistic message sizes
   - Create helper to generate N messages with varying content
   - Set up performance timing utilities

2. Large session tests:
   - Create session with 1000 messages, verify operations remain fast
   - Create session with 10000 messages, measure:
     - addMessage latency
     - getRecentMessages latency
     - getAllMessages latency
   - Assert operations complete within acceptable bounds:
     - addMessage: < 10ms
     - getRecentMessages: < 50ms
     - getAllMessages: < 500ms for 10k messages

3. Memory tests:
   - Track memory before/after large session creation
   - Verify no significant memory leaks after session cleanup
   - Use process.memoryUsage() for measurements

Mark tests as benchmark tests using describe.skip or a custom flag to avoid running in CI unless explicitly requested.
  </action>
  <verify>npm test -- --run src/main/services/__tests__/session-performance.test.ts</verify>
  <done>Large session tests pass, demonstrating acceptable performance at scale</done>
</task>

<task type="auto">
  <name>Task 2: Compaction and concurrent access tests</name>
  <files>src/main/services/__tests__/session-performance.test.ts</files>
  <action>
Add compaction performance and concurrency tests:

1. Compaction performance:
   - Time compaction operation with various checkpoint sizes
   - Mock Claude SDK to avoid real API calls but simulate realistic delay
   - Assert compaction completes < 30 seconds (per roadmap requirement)
   - Test compaction with 100 messages, 1000 messages, 5000 messages

2. Concurrent session access:
   - Create multiple sessions simultaneously
   - Perform parallel read/write operations on different sessions
   - Verify no race conditions or data corruption
   - Use Promise.all with multiple session operations

3. File I/O performance:
   - Measure saveSession and loadSession times
   - Test with varying session sizes
   - Assert file operations complete < 100ms (per roadmap requirement)
   - Test save/load cycle integrity (data matches after round-trip)

4. Edge cases under load:
   - Rapid successive addMessage calls
   - Concurrent getOrCreateSession for same session ID
   - Multiple forceCompact calls in succession
  </action>
  <verify>npm test -- --run src/main/services/__tests__/session-performance.test.ts</verify>
  <done>Compaction and concurrency tests pass, meeting performance requirements</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] All performance tests pass
- [ ] Tests are marked appropriately for CI (benchmark tests can be skipped)
- [ ] Performance assertions match roadmap requirements
- [ ] No race conditions detected in concurrent tests
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- Performance benchmarks documented in test output
- Tests can run in both quick (mocked) and full (real timing) modes
</success_criteria>

<output>
After completion, create `.planning/phases/v3.0-08-testing-polish/08-02-SUMMARY.md`
</output>
