# Milestone v3.1: Task Analysis Orchestrator

## Overview

Replace prompt-based task decomposition with an orchestrator-controlled analysis loop. Instead of PM agent deciding task count upfront during feature creation, the system:

1. **Auto-creates a single task** when feature is created (status: `needs_analysis`)
2. **Orchestrator loops** through all `needs_analysis` tasks
3. **PM analyzes ONE task at a time** - decides: keep as-is → `ready_for_dev`, or split → new subtasks
4. **New subtasks** get `needs_analysis` status
5. **Loop continues** until no `needs_analysis` tasks remain

**Why this approach:**
- **Clear state machine**: Explicit task states vs implicit PM judgment
- **Controlled iteration**: Orchestrator manages loops, PM handles judgment
- **Isolated context**: Each PM call analyzes ONE task with fresh context
- **Auditable decisions**: Each split decision is a separate, traceable event
- **Interruptible**: User can pause/resume, inspect intermediate state

**Success Criteria:**
- Feature creation auto-creates single `needs_analysis` task
- PM analyzes tasks iteratively until all are `ready_for_dev`
- Dependencies established during splits (based on data flow/logical ordering)
- No breaking changes to existing task execution workflow

---

## Phase 1: Task Status Extension

**Goal**: Add `needs_analysis` status and update task flow.

### Tasks

#### 1.1: Add `needs_analysis` Status
**Files**:
- `src/shared/types/task.ts`
- `src/renderer/src/components/DAG/TaskNode.tsx` (status color)

**Changes**:
```typescript
export type TaskStatus =
  | 'needs_analysis'     // NEW: Awaiting PM analysis
  | 'blocked'
  | 'ready_for_dev'
  // ... rest unchanged
```

**Acceptance Criteria**:
- Type definition includes `needs_analysis`
- Status label: "Needs Analysis"
- UI displays distinct color for `needs_analysis` tasks (suggest: purple/violet)
- Task node shows analysis icon or indicator

**Dependencies**: None

---

#### 1.2: Update Feature Creation to Auto-Create Task
**Files**:
- `src/main/storage/feature-store.ts` (createFeature method)
- `src/main/ipc/storage-handlers.ts` (if needed)

**Changes**:
- When feature is created, automatically create one task
- Task title: feature name
- Task description: feature description
- Task status: `needs_analysis`
- No PM agent invocation during creation

**Acceptance Criteria**:
- Creating feature "Add dark mode" creates task "Add dark mode" with `needs_analysis`
- No PM agent runs during feature creation
- DAG shows single purple node immediately after creation

**Dependencies**: 1.1

---

#### 1.3: Update PM Planning Prompt (Remove Task Creation)
**Files**:
- `src/main/agent/pm-agent-manager.ts` (buildPlanningPrompt)
- `src/main/agent/prompt-builders.ts` (PM role instructions)

**Changes**:
- Remove task creation instructions from planning prompt
- Planning now ONLY creates feature-spec.md
- Task creation moved to analysis phase

**Acceptance Criteria**:
- PM planning creates spec.md only
- No tasks created by PM during planning
- Planning verification only checks spec.md exists

**Dependencies**: 1.2

---

## Phase 2: Analysis Orchestrator

**Goal**: Build the orchestrator that loops through `needs_analysis` tasks.

### Tasks

#### 2.1: Create TaskAnalysisOrchestrator Service
**File**: `src/main/services/task-analysis-orchestrator.ts`

```typescript
interface TaskAnalysisOrchestrator {
  // Main entry point - analyze all needs_analysis tasks for a feature
  analyzeFeatureTasks(featureId: string): AsyncGenerator<AnalysisEvent>

  // Analyze a single task
  analyzeTask(featureId: string, taskId: string): Promise<AnalysisResult>

  // Check if feature has pending analysis
  hasPendingAnalysis(featureId: string): Promise<boolean>

  // Get all needs_analysis tasks for a feature
  getPendingTasks(featureId: string): Promise<Task[]>
}

type AnalysisEvent =
  | { type: 'analyzing', taskId: string }
  | { type: 'kept', taskId: string }
  | { type: 'split', taskId: string, newTasks: Task[] }
  | { type: 'complete', featureId: string }
  | { type: 'error', taskId: string, error: string }

interface AnalysisResult {
  decision: 'keep' | 'split'
  newTasks?: Array<{
    title: string
    description: string
    dependsOn?: string[] // IDs of tasks this depends on
  }>
  reasoning?: string
}
```

**Acceptance Criteria**:
- Orchestrator finds all `needs_analysis` tasks
- Processes one task at a time
- Emits events for UI updates
- Handles errors gracefully (marks task as failed, continues)
- Stops when no more `needs_analysis` tasks exist

**Dependencies**: Phase 1 complete

---

#### 2.2: Create PM Analysis Prompt Builder
**File**: `src/main/agent/pm-analysis-prompt.ts`

```typescript
function buildAnalysisPrompt(task: Task, featureSpec: string): string
```

**Prompt structure**:
```
You are analyzing a task to determine if it should be split.

## Feature Spec
{featureSpec}

## Task to Analyze
Title: {task.title}
Description: {task.description}

## Your Decision

Analyze this task's COMPLEXITY and SCOPE:

1. **Estimate the work**: How many distinct implementation steps?
2. **Check independence**: Are there logically separate deliverables?
3. **Consider scope**: Would this be too large for one dev session?

**Decision Options:**

A) **KEEP** - Task is appropriately scoped
   - Single deliverable or tightly coupled items
   - Reasonable amount of work
   - No need to split

B) **SPLIT** - Task is too complex
   - Multiple independent deliverables
   - Would benefit from separate implementation
   - Define subtasks with dependencies

## Output Format

If KEEP:
{
  "decision": "keep"
}

If SPLIT:
{
  "decision": "split",
  "tasks": [
    {
      "title": "...",
      "description": "...",
      "dependsOn": []  // empty = no dependencies
    },
    {
      "title": "...",
      "description": "...",
      "dependsOn": ["task-id-1"]  // depends on first task
    }
  ]
}

IMPORTANT:
- Never create verification/QA tasks (built-in)
- Never create planning tasks
- Use dependsOn when task B needs output from task A
- Keep tasks focused and actionable
```

**Acceptance Criteria**:
- Prompt provides clear decision framework
- JSON output format is parseable
- Dependencies use task IDs

**Dependencies**: 2.1

---

#### 2.3: Implement Analysis Execution
**Files**:
- `src/main/services/task-analysis-orchestrator.ts` (extend)
- `src/main/agent/agent-service.ts` (if needed)

**Changes**:
- Connect orchestrator to AgentService
- Parse PM response JSON
- Create subtasks via DAGManager
- Establish dependencies via DAGAddConnection
- Update original task status

**Acceptance Criteria**:
- PM response parsed correctly
- New tasks created with `needs_analysis` status
- Dependencies added correctly
- Original task removed (if split) or status changed to `ready_for_dev` (if kept)
- Handles malformed PM responses gracefully

**Dependencies**: 2.2

---

#### 2.4: Add Orchestrator IPC Handlers
**File**: `src/main/ipc/analysis-handlers.ts`

```typescript
// IPC handlers:
// - analysis:start (featureId) - Start analysis loop
// - analysis:status (featureId) - Check if analysis running
// - analysis:pending (featureId) - Get pending task count
```

**Acceptance Criteria**:
- Renderer can trigger analysis
- Renderer can check analysis status
- Events streamed to renderer for UI updates

**Dependencies**: 2.3

---

## Phase 3: UI Integration

**Goal**: Expose analysis workflow in the UI.

### Tasks

#### 3.1: Add Analysis Status to Feature Card
**File**: `src/renderer/src/components/FeatureCard.tsx`

**Changes**:
- Show "Analyzing..." badge when analysis running
- Show "X tasks pending analysis" when paused
- Show analysis progress (N/M tasks analyzed)

**Acceptance Criteria**:
- Feature card reflects analysis state
- Badge updates in real-time
- Clear visual distinction from other states

**Dependencies**: 2.4

---

#### 3.2: Add Analysis Controls to DAG View
**File**: `src/renderer/src/views/DAGView.tsx`

**Changes**:
- Add "Analyze Tasks" button (when `needs_analysis` tasks exist)
- Show analysis progress indicator
- Disable task execution while analysis running

**Acceptance Criteria**:
- Button appears when there are `needs_analysis` tasks
- Progress shown during analysis
- Can't start dev work until analysis complete

**Dependencies**: 3.1

---

#### 3.3: Update Task Node for Analysis State
**File**: `src/renderer/src/components/DAG/TaskNode.tsx`

**Changes**:
- Purple/violet color for `needs_analysis` status
- Analysis icon (magnifying glass or similar)
- Tooltip: "This task needs complexity analysis"
- Pulsing animation while being analyzed

**Acceptance Criteria**:
- Visual distinction clear
- Animation only during active analysis
- Consistent with existing status colors

**Dependencies**: 3.2

---

## Phase 4: Automatic Analysis Trigger

**Goal**: Optionally auto-run analysis after feature creation.

### Tasks

#### 4.1: Add Auto-Analysis Setting
**Files**:
- `src/shared/types/settings.ts`
- `src/main/storage/settings-store.ts`
- `src/renderer/src/views/SettingsView.tsx`

**Changes**:
- Add setting: `autoAnalyzeNewFeatures: boolean` (default: true)
- Expose in settings UI

**Acceptance Criteria**:
- Setting persisted
- Toggle in settings view
- Default is enabled

**Dependencies**: Phase 3 complete

---

#### 4.2: Trigger Analysis After Feature Creation
**File**: `src/main/agent/pm-agent-manager.ts`

**Changes**:
- After spec creation completes, check setting
- If auto-analyze enabled, start analysis orchestrator
- Emit events for UI updates

**Acceptance Criteria**:
- Analysis runs automatically if enabled
- User can disable in settings
- Works seamlessly with existing workflow

**Dependencies**: 4.1

---

#### 4.3: Handle Manual Analysis Trigger
**Files**:
- `src/renderer/src/views/DAGView.tsx`
- `src/main/ipc/analysis-handlers.ts`

**Changes**:
- "Analyze" button for manual trigger
- Works when auto-analysis is disabled
- Works for existing features with `needs_analysis` tasks

**Acceptance Criteria**:
- Manual trigger works
- Can re-analyze if needed (adds new `needs_analysis` tasks)
- Clear UI feedback

**Dependencies**: 4.2

---

## Phase 5: Testing & Polish

**Goal**: Ensure reliability and good UX.

### Tasks

#### 5.1: Unit Tests for Orchestrator
**File**: `src/main/services/__tests__/task-analysis-orchestrator.test.ts`

**Tests**:
- Single task kept (no split)
- Single task split into 2
- Recursive split (task → subtasks → sub-subtasks)
- Dependencies established correctly
- Error handling (PM malformed response)
- Loop termination

**Acceptance Criteria**:
- All test cases pass
- Edge cases covered
- Good coverage of orchestrator logic

**Dependencies**: Phase 4 complete

---

#### 5.2: Integration Tests
**File**: `src/main/services/__tests__/task-analysis-integration.test.ts`

**Tests**:
- Full flow: feature creation → spec → analysis → ready_for_dev
- Analysis with existing DAG tasks
- Concurrent analysis prevention
- UI event emission

**Acceptance Criteria**:
- End-to-end flow works
- No race conditions
- Events received correctly

**Dependencies**: 5.1

---

#### 5.3: Update PM Prompts for Consistency
**Files**:
- `src/main/agent/prompt-builders.ts`
- `src/main/agent/pm-agent-manager.ts`

**Changes**:
- Remove task creation from PM planning entirely
- Ensure PM chat can still create tasks manually (via DAGAddNode)
- Consistent messaging about analysis workflow

**Acceptance Criteria**:
- PM understands new workflow
- Can answer questions about task analysis
- Doesn't try to create tasks during planning

**Dependencies**: 5.2

---

## Success Metrics

### Functional
- [ ] Feature creation auto-creates single `needs_analysis` task
- [ ] Orchestrator processes all tasks until none remain
- [ ] Dependencies established correctly during splits
- [ ] No breaking changes to task execution

### Quality
- [ ] PM makes reasonable split decisions
- [ ] Analysis completes in reasonable time (< 30s per task)
- [ ] UI clearly shows analysis progress
- [ ] Errors handled gracefully

### UX
- [ ] User understands workflow without documentation
- [ ] Can intervene/pause analysis if needed
- [ ] Clear feedback on what's happening

---

## Risks & Mitigations

### Risk 1: Over-splitting
**Description**: PM splits tasks too aggressively, creating many tiny tasks

**Mitigation**:
- Prompt emphasizes "keep unless clearly too complex"
- Review split decisions in UI before execution
- Allow manual task merging (future feature)

### Risk 2: Under-splitting
**Description**: PM keeps tasks that should be split

**Mitigation**:
- Prompt gives clear complexity indicators
- User can manually re-analyze specific tasks
- Dev agent can request split during execution (future feature)

### Risk 3: Infinite Loops
**Description**: PM splits task A into B and C, then splits B back into something resembling A

**Mitigation**:
- Track split history in task metadata
- Limit max split depth (e.g., 3 levels)
- Alert user if loop detected

### Risk 4: Dependency Cycles
**Description**: PM creates circular dependencies during splits

**Mitigation**:
- DAGManager already validates no cycles
- If cycle detected, reject split and keep task as-is
- Log warning for debugging

---

## Dependency Graph

```
Phase 1: Status Extension
  1.1 needs_analysis status
    └─> 1.2 Auto-create task on feature
          └─> 1.3 Remove task creation from PM planning

Phase 2: Orchestrator
  2.1 TaskAnalysisOrchestrator service
    └─> 2.2 PM Analysis prompt builder
          └─> 2.3 Analysis execution
                └─> 2.4 IPC handlers

Phase 3: UI Integration
  3.1 Feature card analysis status
    └─> 3.2 DAG view controls
          └─> 3.3 Task node styling

Phase 4: Auto-trigger
  4.1 Auto-analysis setting
    └─> 4.2 Trigger after feature creation
          └─> 4.3 Manual trigger support

Phase 5: Testing
  5.1 Unit tests
    └─> 5.2 Integration tests
          └─> 5.3 PM prompt cleanup
```

---

## Notes

- This milestone replaces prompt-based task decomposition with a structured orchestrator approach
- PM still uses judgment, but within a controlled loop
- Existing tasks with `ready_for_dev` or later status are unaffected
- Migration: existing features may need manual re-analysis if tasks weren't split well
